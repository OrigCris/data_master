{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7668694c",
   "metadata": {},
   "source": [
    "\n",
    "# Silver — URA\n",
    "\n",
    "Este notebook **atualiza a tabela Silver de URA** consumindo **apenas as mudanças** da Bronze por **Change Data Feed (CDF)** e aplicando **MERGE**.\n",
    "O processo usa uma **tabela de controle** que guarda a última versão (`_commit_version`) aplicada.\n",
    "\n",
    "**Fluxo**\n",
    "1. Lê o **marcador** de versão na tabela de controle.\n",
    "2. Lê o **CDF** da Bronze desde esse marcador.\n",
    "3. Faz **parse mínimo** do `body` (JSON) com `StructType`, renomeia colunas e deriva campos de data.\n",
    "4. **Garante** que a Silver exista com o **mesmo schema** do staged (criação segura).\n",
    "5. Aplica **MERGE** por chave de negócio.\n",
    "6. Atualiza o **marcador** com a maior versão aplicada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678bff23",
   "metadata": {},
   "source": [
    "\n",
    "## Parâmetros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===================== PARÂMETROS =====================\n",
    "CATALOG        = \"prd\"\n",
    "BRONZE_SCHEMA  = \"b_dm_callcenter\"\n",
    "SILVER_SCHEMA  = \"s_dm_callcenter\"\n",
    "BRONZE_TABLE   = \"ura_once\"\n",
    "SILVER_TABLE   = \"tabe_ura_anlt\"\n",
    "\n",
    "# FQNs\n",
    "BRONZE_FQN = f\"{CATALOG}.{BRONZE_SCHEMA}.{BRONZE_TABLE}\"\n",
    "SILVER_FQN = f\"{CATALOG}.{SILVER_SCHEMA}.{SILVER_TABLE}\"\n",
    "\n",
    "# Tabela de controle\n",
    "CTRL_TBL_FQN = f\"{CATALOG}.{SILVER_SCHEMA}.__last_processed_version\"\n",
    "\n",
    "print(\"Bronze:\", BRONZE_FQN)\n",
    "print(\"Silver:\", SILVER_FQN)\n",
    "print(\"Ctrl  :\", CTRL_TBL_FQN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8ae6f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3835de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, types as T, Window as W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519c52c",
   "metadata": {},
   "source": [
    "\n",
    "## Helpers — Tabela de controle\n",
    "Lê/atualiza o marcador de versão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852c8f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_last_version(src_fqn: str) -> int:\n",
    "    \"\"\"Retorna a última versão (_commit_version) processada para a fonte.\"\"\"\n",
    "    row = (spark.table(CTRL_TBL_FQN)\n",
    "             .filter(F.col(\"source_table\")==src_fqn)\n",
    "             .select(\"last_version\")\n",
    "             .limit(1)\n",
    "             .collect())\n",
    "    return int(row[0][0]) if row else 0\n",
    "\n",
    "def set_last_version(src_fqn: str, new_version: int):\n",
    "    \"\"\"Atualiza o marcador com a última versão aplicada.\"\"\"\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO {CTRL_TBL_FQN} t\n",
    "        USING (SELECT '{src_fqn}' AS source_table, {int(new_version)} AS last_version, current_timestamp() AS last_run_at) s\n",
    "        ON t.source_table = s.source_table\n",
    "        WHEN MATCHED THEN UPDATE SET *\n",
    "        WHEN NOT MATCHED THEN INSERT *\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10c8f9",
   "metadata": {},
   "source": [
    "\n",
    "## Leitura do CDF da Bronze\n",
    "Lê apenas mudanças a partir do `startingVersion`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_bronze_cdf(src_fqn: str, starting_version: int):\n",
    "    return (spark.read\n",
    "            .format(\"delta\")\n",
    "            .option(\"readChangeFeed\", \"true\")\n",
    "            .option(\"startingVersion\", starting_version)\n",
    "            .table(src_fqn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e6352",
   "metadata": {},
   "source": [
    "\n",
    "## Transformação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c531e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform(df_raw):\n",
    "    # Schema do JSON\n",
    "    schema = T.StructType([\n",
    "        T.StructField(\"id_chamada\", T.StringType(),  True),\n",
    "        T.StructField(\"id_cliente\", T.StringType(),  True),\n",
    "        T.StructField(\"id_fila\", T.StringType(),     True),\n",
    "        T.StructField(\"data_hora_inicio\", T.TimestampType(), True),\n",
    "        T.StructField(\"data_hora_fim\",    T.TimestampType(), True),\n",
    "        T.StructField(\"autenticado\", T.BooleanType(), True),\n",
    "        T.StructField(\"opcoes_navegadas\", T.IntegerType(), True),\n",
    "        T.StructField(\"codigo_opcao\", T.StringType(),  True),\n",
    "        T.StructField(\"derivado_atendimento\", T.BooleanType(), True),\n",
    "    ])\n",
    "\n",
    "    rename = {\n",
    "        \"id_chamada\":          \"ID_CHAM\",\n",
    "        \"id_cliente\":          \"ID_CLIE\",\n",
    "        \"id_fila\":             \"ID_FILA\",\n",
    "        \"data_hora_inicio\":    \"DH_INIC\",\n",
    "        \"data_hora_fim\":       \"DH_FIM\",\n",
    "        \"opcoes_navegadas\":    \"QT_OPCA_NAVG\",\n",
    "        \"codigo_opcao\":        \"CD_ULTI_OPCA\",\n",
    "        \"autenticado\":         \"IN_AUTN\",\n",
    "        \"derivado_atendimento\":\"IN_DERV_ATEN\",\n",
    "    }\n",
    "\n",
    "    df = (df_raw\n",
    "          .withColumn(\"body\", F.from_json(F.col(\"body\"), schema))\n",
    "          .filter(F.col(\"body\").isNotNull())\n",
    "          .withColumn(\"_cv\", F.col(\"_commit_version\").cast(\"long\"))\n",
    "          .withColumn(\"_ct\", F.col(\"_commit_timestamp\").cast(\"timestamp\"))\n",
    "          .select(\"body.*\", \"_cv\", \"_ct\")\n",
    "    )\n",
    "\n",
    "    # Renomeia as colunas\n",
    "    df = df.select([F.col(c).alias(rename.get(c, c)) for c in df.columns])\n",
    "\n",
    "    # Colunas de DATA do evento e carga\n",
    "    df = (df\n",
    "          .withColumn(\"CD_PERI\", F.date_format(F.col(\"DH_INIC\"), \"yyyyMM\").cast(\"int\"))\n",
    "          .withColumn(\"DT_INIC\", F.to_date(\"DH_INIC\"))\n",
    "          .withColumn(\"DT_FIM\",  F.to_date(\"DH_FIM\"))\n",
    "          .withColumn(\"DH_REFE_CRGA\", F.current_timestamp())\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721fc122",
   "metadata": {},
   "source": [
    "## Garantir criação da Silver com o **mesmo schema** do staged\n",
    "Cria a tabela **vazia** com o schema do `staged_df` se ela ainda não existir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_table_exists(silver_fqn: str, staged_df):\n",
    "    parts = silver_fqn.split(\".\")\n",
    "    if len(parts) != 3:\n",
    "        raise ValueError(f\"FQN inválido: {silver_fqn}. Use catalog.schema.table\")\n",
    "    \n",
    "    # Checa existência via catálogo\n",
    "    if not spark.catalog.tableExists(silver_fqn):\n",
    "        empty = spark.createDataFrame([], staged_df.schema)\n",
    "        (empty.write\n",
    "              .format(\"delta\")\n",
    "              .mode(\"overwrite\")\n",
    "              .saveAsTable(silver_fqn))\n",
    "        spark.sql(f\"ALTER TABLE {silver_fqn} CLUSTER BY (CD_PERI,DT_INIC,ID_CHAM)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a6eee",
   "metadata": {},
   "source": [
    "## MERGE\n",
    "- **MATCHED** → `UPDATE SET *`\n",
    "- **NOT MATCHED** → `INSERT *`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ff2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge(silver_fqn: str, staged_df, keys):\n",
    "    ensure_table_exists(silver_fqn, staged_df)\n",
    "    staged_df.createOrReplaceTempView(\"_stg_silver_ura\")\n",
    "    on_clause = \" AND \".join([f\"S.{k} = C.{k}\" for k in keys])\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO {silver_fqn} AS S\n",
    "        USING _stg_silver_ura AS C\n",
    "        ON {on_clause}\n",
    "        WHEN MATCHED THEN UPDATE SET *\n",
    "        WHEN NOT MATCHED THEN INSERT *\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fec2b1",
   "metadata": {},
   "source": [
    "\n",
    "## ▶️ Execução\n",
    "1) Lê marcador → 2) Lê CDF → 3) Filtra inserts → 4) Transforma → 5) MERGE → 6) Atualiza marcador.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4160d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) marcador\n",
    "last_v = get_last_version(BRONZE_FQN)\n",
    "print(f\"Última versão processada (CDF) para {BRONZE_FQN}: {last_v}\")\n",
    "\n",
    "# 2) CDF\n",
    "df_bronze = read_bronze_cdf(BRONZE_FQN, starting_version=last_v)\n",
    "\n",
    "# 3) Capturando as mudanças\n",
    "df_cdf = df_bronze.filter(F.col(\"_change_type\").isin(\"insert\"))\n",
    "\n",
    "# 4) TRANSFORMAÇÃO\n",
    "df_staged = transform(df_cdf)\n",
    "\n",
    "# 5) MERGE\n",
    "merge(SILVER_FQN, df_staged, keys=[\"ID_CHAM\"])\n",
    "\n",
    "# 6) atualizar marcador com a MAIOR versão\n",
    "max_version = df_cdf.agg(F.max(\"_commit_version\")).first()[0]\n",
    "if max_version is not None:\n",
    "    set_last_version(BRONZE_FQN, int(max_version))\n",
    "    print(f\"Marcador atualizado → last_version = {int(max_version)}\")\n",
    "else:\n",
    "    print(\"Nenhuma mudança nova no CDF (nada a atualizar).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
