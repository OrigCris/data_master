{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d3e0af3",
   "metadata": {},
   "source": [
    "\n",
    "# Unity Catalog – Criação de SCHEMAS por camada (Bronze / Silver / Gold)\n",
    "\n",
    "Este notebook cria **schemas nomeados por aplicação e camada** no **Unity Catalog**, seguindo o padrão:\n",
    "\n",
    "- Prefixos de camada:\n",
    "  - `b_*` → **Bronze**\n",
    "  - `s_*` → **Silver**\n",
    "  - `g_*` → **Gold**\n",
    "- Convenção de nomes: `catalog.schema.tabela` (ex.: `prd.b_dm_callcenter.minha_tabela`)\n",
    "- Cada **schema** recebe uma **MANAGED LOCATION** no ADLS organizada por camada:\n",
    "  - `abfss://<container>@<storage>.dfs.core.windows.net/<camada>`\n",
    "\n",
    "> ✅ **Pré-requisitos**\n",
    "> - Workspace com **Unity Catalog** habilitado\n",
    "> - Permissão para **CREATE SCHEMA** no catálogo\n",
    "> - **RBAC** no **Storage Account** que hospeda o container\n",
    ">\n",
    "> 🔎 **O que este notebook faz**\n",
    "> 1. Valida o catálogo informado.\n",
    "> 2. Cria schemas em lote com **MANAGED LOCATION** por camada.\n",
    "> 3. Faz *fallback* (criação sem location) caso falte permissão.\n",
    "> 4. Mostra um **resumo** do que foi criado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd134f2",
   "metadata": {},
   "source": [
    "## Parâmetros editáveis\n",
    "Ajuste o catálogo, storage, container e a lista de schemas que deseja criar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195bef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== PARÂMETROS EDITÁVEIS =====================\n",
    "catalog_name         = \"prd\"                 # catálogo UC (ex.: prd)\n",
    "storage_account_name = \"stacjtecprd001\"      # nome do Storage Account (ADLS Gen2)\n",
    "container_name       = \"ctcjtecprd001\"       # nome do container\n",
    "# Schemas a criar (pode adicionar/remover conforme necessidade)\n",
    "schemas_desejados = [\n",
    "    \"b_dm_callcenter\",\n",
    "    \"s_dm_callcenter\",\n",
    "    \"g_dm_callcenter\",\n",
    "]\n",
    "\n",
    "print(\"Catálogo:\", catalog_name)\n",
    "print(\"Storage :\", storage_account_name)\n",
    "print(\"Container:\", container_name)\n",
    "print(\"Schemas :\", schemas_desejados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb585f4",
   "metadata": {},
   "source": [
    "## Funções auxiliares\n",
    "- **`prefixo_para_camada`**: infere `bronze|silver|gold` a partir do prefixo do schema.\n",
    "- **`managed_location`**: monta a URL ABFS para **MANAGED LOCATION** por camada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b657b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "def prefixo_para_camada(schema_name: str) -> str:\n",
    "    \"\"\"Retorna a camada (bronze/silver/gold) com base no prefixo do schema.\"\"\"\n",
    "    if schema_name.startswith(\"b_\"):\n",
    "        return \"bronze\"\n",
    "    if schema_name.startswith(\"s_\"):\n",
    "        return \"silver\"\n",
    "    if schema_name.startswith(\"g_\"):\n",
    "        return \"gold\"\n",
    "    raise ValueError(f\"Schema '{schema_name}' inválido: prefixo deve ser 'b_', 's_' ou 'g_'.\")\n",
    "\n",
    "def managed_location(layer: str) -> str:\n",
    "    \"\"\"Monta o caminho ABFS para a MANAGED LOCATION da camada.\"\"\"\n",
    "    return f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/{layer}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b2c9e",
   "metadata": {},
   "source": [
    "\n",
    "## ▶️ Execução\n",
    "1. Valida o catálogo\n",
    "2. Cria os schemas com **MANAGED LOCATION** (ou fallback)\n",
    "3. Exibe um **resumo**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2596e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"==> Validando catálogo...\")\n",
    "try:\n",
    "    spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "    print(f\"[OK] Catálogo encontrado: {catalog_name}\")\n",
    "except AnalysisException as e:\n",
    "    raise Exception(\n",
    "        f\"Catálogo '{catalog_name}' não encontrado ou sem permissão. \"\n",
    "        f\"Crie/ajuste antes de prosseguir.\"\n",
    "    ) from e\n",
    "\n",
    "print(\"==> Criando schemas com MANAGED LOCATION por camada...\")\n",
    "criadas, fallback = [], []\n",
    "for schema in schemas_desejados:\n",
    "    layer = prefixo_para_camada(schema)   # bronze/silver/gold\n",
    "    mloc  = managed_location(layer)       # URL ABFS para MANAGED LOCATION\n",
    "    fqn   = f\"{catalog_name}.{schema}\"    # nome completo do schema\n",
    "    try:\n",
    "        spark.sql(f\"\"\"\n",
    "            CREATE SCHEMA IF NOT EXISTS {fqn}\n",
    "            MANAGED LOCATION '{mloc}'\n",
    "        \"\"\")\n",
    "        criadas.append((fqn, layer, mloc, \"managed\"))\n",
    "        print(f\"[✓] {fqn:<45} | camada={layer:<6} | MANAGED LOCATION={mloc}\")\n",
    "    except AnalysisException as e:\n",
    "        # Fallback: cria sem caminho (usa o storage root do catálogo)\n",
    "        spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {fqn}\")\n",
    "        fallback.append((fqn, layer, getattr(e, \"desc\", str(e))))\n",
    "        print(f\"[!] {fqn:<45} | camada={layer:<6} | sem MANAGED LOCATION (fallback). Motivo: {getattr(e,'desc',e)}\")\n",
    "\n",
    "print(\"\\n==> Resumo\")\n",
    "for fqn, layer, mloc, _ in criadas:\n",
    "    print(f\" - {fqn}  →  MANAGED LOCATION = {mloc}  (camada={layer})\")\n",
    "for fqn, layer, err in fallback:\n",
    "    print(f\" - {fqn}  →  criado SEM managed location (fallback). camada={layer}. \"\n",
    "          f\"Ajuste permissões e rode: ALTER SCHEMA {fqn} SET MANAGED LOCATION '<path>';\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daf6de3",
   "metadata": {},
   "source": [
    "\n",
    "## 🔎 Validação (opcional)\n",
    "Use os comandos abaixo para inspecionar as MANAGED LOCATIONs e confirmar as permissões.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista os schemas do catálogo\n",
    "spark.sql(f\"SHOW SCHEMAS IN {catalog_name}\").display()\n",
    "\n",
    "# Mostra detalhes dos schemas criados (inclui localização gerenciada quando definida)\n",
    "for s in schemas_desejados:\n",
    "    fqn = f\"{catalog_name}.{s}\"\n",
    "    print(f\"\\n--- DESCRIBE SCHEMA EXTENDED {fqn} ---\")\n",
    "    spark.sql(f\"DESCRIBE SCHEMA EXTENDED {fqn}\").display()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
